{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84270,"databundleVersionId":9826512,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm  # Import tqdm for progress tracking\n\n\nclass TrajectoryDataset(Dataset):\n    def __init__(self, dataframe, window_length=100):\n        # Perform the custom transformation\n        sliced_df = self.custom_transformation(dataframe.to_numpy(), window_length=window_length)\n        self.data = torch.tensor(sliced_df, dtype=torch.float32)\n\n    def __len__(self):\n        # Return the number of trajectories\n        return self.data.shape[0]\n\n    def __getitem__(self, idx):\n        # Get the trajectory at the given index\n        return self.data[idx]\n\n    def custom_transformation(self, dataframe_array, window_length):\n        num_rows, num_cols = dataframe_array.shape\n        window_length += 1  # get one more column as targets\n\n        # Preallocate memory for the slices\n        sliced_data = np.lib.stride_tricks.sliding_window_view(dataframe_array, window_shape=(window_length,), axis=1)\n        \n        # Reshape into a flat 2D array for DataFrame-like output\n        sliced_data = sliced_data.reshape(-1, window_length)\n\n        return sliced_data\n    \n# Implement your model\nclass MLP(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-10-11T19:36:12.696463Z","iopub.execute_input":"2024-10-11T19:36:12.696909Z","iopub.status.idle":"2024-10-11T19:36:16.403558Z","shell.execute_reply.started":"2024-10-11T19:36:12.696859Z","shell.execute_reply":"2024-10-11T19:36:16.402470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{}},{"cell_type":"code","source":"import os\n\n# Get the relative path of a file in the current working directory\ntrain_path = os.path.join('/kaggle/input/cse-575-project-2/train.csv')\nval_path = os.path.join('/kaggle/input/cse-575-project-2/val.csv')\ntest_path = os.path.join('/kaggle/input/cse-575-project-2/test.csv')\n\ntrain_df = pd.read_csv(train_path, header = 0).drop('ids', axis=1)\nval_df = pd.read_csv(val_path, header = 0).drop('ids', axis=1)\ntest_df = pd.read_csv(test_path, header = 0).drop('ids', axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T19:36:16.405984Z","iopub.execute_input":"2024-10-11T19:36:16.407002Z","iopub.status.idle":"2024-10-11T19:36:19.680943Z","shell.execute_reply.started":"2024-10-11T19:36:16.406942Z","shell.execute_reply":"2024-10-11T19:36:19.679710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if MPS is available and set the device accordingly\ndevice = torch.device('cpu')\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n\nwindow_length = 100  # Example window length\ndataset = TrajectoryDataset(dataframe=train_df, window_length=window_length)\nbatch_size = 32\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Model hyperparameters\ninput_size = window_length  # Window length minus 1 (since the last column is the target)\nhidden_size = 64\noutput_size = 1  # Single output for time series forecast (next value)\nlearning_rate = 0.001\nnum_epochs = 1\n\n# Instantiate the model, loss function, and optimizer\nmodel = MLP(input_size, hidden_size, output_size).to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Training loop with tqdm for progress tracking\nfor epoch in tqdm(range(num_epochs), desc=\"Epochs\", unit=\"epoch\"):\n    model.train()\n    running_loss = 0.0\n    # Use tqdm to track batch progress within each epoch\n    for batch_idx, data in tqdm(enumerate(dataloader), desc=f\"Epoch {epoch + 1}\", unit=\"batch\", leave=False):\n        # Separate inputs and targets\n        inputs = data[:, :-1].to(device)  # All except last column\n        targets = data[:, -1].to(device)  # Last column is the target (next value)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(inputs)\n        \n        # Compute the loss\n        loss = criterion(outputs.squeeze(), targets)\n        \n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    # Print the average loss per epoch\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-11T19:36:19.682168Z","iopub.execute_input":"2024-10-11T19:36:19.682477Z","iopub.status.idle":"2024-10-11T19:41:18.441352Z","shell.execute_reply.started":"2024-10-11T19:36:19.682447Z","shell.execute_reply":"2024-10-11T19:41:18.440447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation Loop","metadata":{}},{"cell_type":"code","source":"from torch.nn import MSELoss\n\n\ntrain_set = torch.tensor(train_df.values[:,:].astype(np.float32), dtype=torch.float32)\nval_set = torch.tensor(val_df.values[:,:].astype(np.float32), dtype=torch.float32)\ntest_set = torch.tensor(val_df.values[:,:].astype(np.float32), dtype=torch.float32)\n\npoints_to_predict = val_set.shape[1]\n\n# Autoregressive prediction function\ndef autoregressive_predict(model, input_maxtrix, prediction_length=points_to_predict):\n    \"\"\"\n    Perform autoregressive prediction using the learned model.\n    \n    Args:\n    - model: The trained PyTorch model.\n    - input_maxtrix: A matrix of initial time steps (e.g., shape (963, window_length)).\n    - prediction_length: The length of the future trajectory to predict.\n    \n    Returns:\n    - output_matrix: A tensor of the predicted future trajectory of the same length as `prediction_length`.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n    output_matrix = torch.empty(input_maxtrix.shape[0],0)\n    current_input = input_maxtrix\n    \n    with torch.no_grad():  # No need to calculate gradients for prediction\n        for _ in range(prediction_length):\n            # Predict the next time step\n            next_pred = model(current_input)\n            # Concatenating the new column along dimension 1 (columns)\n            output_matrix = torch.cat((output_matrix, next_pred), dim=1)\n            \n            # Use the predicted value as part of the next input\n            current_input = torch.cat((current_input[:, 1:],next_pred),dim=1)\n    \n    return output_matrix\n\n\ninitial_input = train_set[:, -window_length:]  #use the last window of training set as initial input\nfull_trajectories = autoregressive_predict(model, initial_input,)\n\n\n# Calculate MSE between predicted trajectories and actual validation trajectories using torch\nmse_loss = MSELoss()\n\n# Compute MSE\nmse = mse_loss(full_trajectories, val_set)\n\n# Print MSE\nprint(f'Autoregressive Validation MSE (using torch): {mse.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-10-11T19:41:18.442645Z","iopub.execute_input":"2024-10-11T19:41:18.443171Z","iopub.status.idle":"2024-10-11T19:41:19.182960Z","shell.execute_reply.started":"2024-10-11T19:41:18.443134Z","shell.execute_reply":"2024-10-11T19:41:19.181866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot it out to see what is like","metadata":{}},{"cell_type":"code","source":"# Perform autoregressive predictions for one row in the validation set\n# We can pick a specific row (e.g., row 0) to visualize\nrow_idx = 0  # You can change this to visualize predictions for different rows\ninitial_input = val_set[row_idx, :window_length].unsqueeze(0)\n\n# Predict future trajectory of length 100\npredicted_trajectory = autoregressive_predict(model, initial_input)\n\n# Get the actual trajectory for comparison\nactual_trajectory = val_set[row_idx].numpy()\n\n# Plot the actual vs predicted trajectory\nplt.figure(figsize=(10, 6))\nplt.plot(range(len(actual_trajectory)), actual_trajectory, label=\"Actual Trajectory\", color='blue', marker='o')\nplt.plot(range(len(actual_trajectory)), predicted_trajectory.squeeze().numpy(), label=\"Predicted Trajectory\", color='red', linestyle='--', marker='x')\nplt.title(f\"Actual vs Predicted Trajectory (Row {row_idx})\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"Value\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T19:41:19.185049Z","iopub.execute_input":"2024-10-11T19:41:19.185378Z","iopub.status.idle":"2024-10-11T19:41:19.794705Z","shell.execute_reply.started":"2024-10-11T19:41:19.185346Z","shell.execute_reply":"2024-10-11T19:41:19.793696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate predictions for all the validation dataset\nval_predictions = []\nfor i in tqdm(range(val_set.shape[0])):\n    initial_input = val_set[i, :window_length].unsqueeze(0)\n    predicted_trajectory = autoregressive_predict(model, initial_input)\n    val_predictions.append(predicted_trajectory.squeeze().numpy())\n\n# Generate predictions for all the testing dataset\ntest_predictions = []\nfor i in tqdm(range(test_set.shape[0])):\n    initial_input = test_set[i, :window_length].unsqueeze(0)\n    predicted_trajectory = autoregressive_predict(model, initial_input)\n    test_predictions.append(predicted_trajectory.squeeze().numpy())\n\n# Convert the list of predictions into tensors\nval_predictions_tensor = torch.tensor(val_predictions)\ntest_predictions_tensor = torch.tensor(test_predictions)\n\n# Print their shapes\nprint(f'Validation Predictions Tensor Shape: {val_predictions_tensor.shape}')\nprint(f'Test Predictions Tensor Shape: {test_predictions_tensor.shape}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T19:41:19.796178Z","iopub.execute_input":"2024-10-11T19:41:19.796517Z","iopub.status.idle":"2024-10-11T19:44:15.305342Z","shell.execute_reply.started":"2024-10-11T19:41:19.796483Z","shell.execute_reply":"2024-10-11T19:44:15.304181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_submissions_v2(pred_val_tensor, pred_test_tensor, original_val_path, original_test_path):\n    # Read the original validation and testing datasets\n    original_val_df = pd.read_csv(original_val_path)\n    original_test_df = pd.read_csv(original_test_path)\n\n    # Ensure the shape of pred_val_tensor and pred_test_tensor is correct\n    assert pred_val_tensor.shape[0] * pred_val_tensor.shape[1] == original_val_df.shape[0] * (original_val_df.shape[1] - 1)\n    assert pred_test_tensor.shape[0] * pred_test_tensor.shape[1] == original_test_df.shape[0] * (original_test_df.shape[1] - 1)\n\n    # Create empty lists to store ids and values\n    ids = []\n    values = []\n\n    # Process validation set\n    for col_idx, col in enumerate(original_val_df.columns[1:]):  # Skip the 'ids' column\n        for row_idx, _ in enumerate(original_val_df[col]):\n            ids.append(str(f\"{col}_traffic_val_{row_idx}\"))\n            values.append(float(pred_val_tensor[row_idx, col_idx]))\n\n    # Process testing set\n    for col_idx, col in enumerate(original_test_df.columns[1:]):  # Skip the 'ids' column\n        for row_idx, _ in enumerate(original_test_df[col]):\n            ids.append(str(f\"{col}_traffic_test_{row_idx}\"))\n            values.append(float(pred_test_tensor[row_idx, col_idx]))\n\n    # Create the submissions dataframe\n    submissions_df = pd.DataFrame({\n        \"ids\": ids,\n        \"value\": values\n    })\n\n    # Assert the shape of the dataframe\n    assert submissions_df.shape[1] == 2\n    assert submissions_df.shape[0] == (original_val_df.shape[0] * (original_val_df.shape[1] - 1)) + (original_test_df.shape[0] * (original_test_df.shape[1] - 1))\n    assert \"ids\" in submissions_df.columns\n    assert \"value\" in submissions_df.columns\n    assert submissions_df['value'].isnull().sum() == 0\n\n    # Save to CSV\n    submissions_df.to_csv('submissions_v3.csv', index=False)\n\n# Call the function\ngenerate_submissions_v2(val_predictions_tensor, test_predictions_tensor, '/kaggle/input/cse-575-project-2/val.csv', '/kaggle/input/cse-575-project-2/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-11T20:04:09.395629Z","iopub.execute_input":"2024-10-11T20:04:09.396442Z","iopub.status.idle":"2024-10-11T20:04:38.139124Z","shell.execute_reply.started":"2024-10-11T20:04:09.396393Z","shell.execute_reply":"2024-10-11T20:04:38.138019Z"},"trusted":true},"execution_count":null,"outputs":[]}]}