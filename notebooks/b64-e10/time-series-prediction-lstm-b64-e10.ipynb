{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26993,"status":"ok","timestamp":1730160551937,"user":{"displayName":"Nishal Chandra Reddy","userId":"06667136568360495769"},"user_tz":420},"id":"ktzL_yM7GCYB","outputId":"3b86ac6c-bcd9-4a27-d949-5835506cc23a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3095,"status":"ok","timestamp":1730160571661,"user":{"displayName":"Nishal Chandra Reddy","userId":"06667136568360495769"},"user_tz":420},"id":"CQfpXXI6L_NB"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm  # Import tqdm for progress tracking\n","\n","\n","class TrajectoryDataset(Dataset):\n","    def __init__(self, dataframe, window_length=100):\n","        # Perform the custom transformation\n","        sliced_df = self.custom_transformation(dataframe.to_numpy(), window_length=window_length)\n","        self.data = torch.tensor(sliced_df, dtype=torch.float32)\n","\n","    def __len__(self):\n","        # Return the number of trajectories\n","        return self.data.shape[0]\n","\n","    def __getitem__(self, idx):\n","        # Get the trajectory at the given index\n","        return self.data[idx]\n","\n","    def custom_transformation(self, dataframe_array, window_length):\n","        num_rows, num_cols = dataframe_array.shape\n","        window_length += 1  # get one more column as targets\n","\n","        # Preallocate memory for the slices\n","        sliced_data = np.lib.stride_tricks.sliding_window_view(dataframe_array, window_shape=(window_length,), axis=1)\n","\n","        # Reshape into a flat 2D array for DataFrame-like output\n","        sliced_data = sliced_data.reshape(-1, window_length)\n","\n","        return sliced_data\n","\n","# LSTM model\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(LSTMModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"GbLEt3JJL_NG"},"source":["## Training loop"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10150,"status":"ok","timestamp":1730160581802,"user":{"displayName":"Nishal Chandra Reddy","userId":"06667136568360495769"},"user_tz":420},"id":"3NX2jH76L_NM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8498b11-6845-4031-cfd1-133be6e6af22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data shape: (963, 7560)\n","Validation data shape: (963, 1500)\n","Testing data shape: (963, 1500)\n"]}],"source":["import os\n","\n","# dataset_path = \"./dataset/\"\n","dataset_path = \"/content/drive/Othercomputers/My Laptop/Sem_3/CSE_575_SML/Projects/Individual_Project/dataset/\"\n","\n","# Get the relative path of a file in the current working directory\n","train_path = os.path.join(dataset_path + 'train.csv')\n","val_path = os.path.join(dataset_path+ 'val.csv')\n","test_path = os.path.join(dataset_path+'test.csv')\n","\n","train_df = pd.read_csv(train_path, header = 0).drop('ids', axis=1)\n","val_df = pd.read_csv(val_path, header = 0).drop('ids', axis=1)\n","test_df = pd.read_csv(test_path, header = 0).drop('ids', axis=1)\n","\n","# print the training data shape\n","print(f\"Training data shape: {train_df.shape}\")\n","print(f\"Validation data shape: {val_df.shape}\")\n","print(f\"Testing data shape: {test_df.shape}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1u7EpQBCgviAju8nVs-XAVQgtlxESMDBn"},"id":"0a2wcGz-L_NN","scrolled":true,"executionInfo":{"status":"ok","timestamp":1730165762588,"user_tz":420,"elapsed":5914,"user":{"displayName":"Nishal Chandra Reddy","userId":"06667136568360495769"}},"outputId":"919d6951-f2bd-45f8-ea13-6abb5e449917"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Check if MPS is available and set the device accordingly\n","device = torch.device('cpu')\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","\n","# Hyperparameters\n","window_length = 100\n","batch_size = 64\n","input_size = 1  # For univariate time series\n","hidden_size = 64\n","num_layers = 2\n","output_size = 1\n","learning_rate = 0.001\n","num_epochs = 10\n","\n","\n","# Prepare dataset and dataloader\n","dataset = TrajectoryDataset(dataframe=train_df, window_length=window_length)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Instantiate the model, loss function, and optimizer\n","model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop with tqdm for progress tracking\n","for epoch in tqdm(range(num_epochs), desc=\"Epochs\", unit=\"epoch\"):\n","    model.train()\n","    running_loss = 0.0\n","\n","    # Use tqdm to track batch progress within each epoch\n","    for batch_idx, data in tqdm(enumerate(dataloader), desc=f\"Epoch {epoch + 1}\", unit=\"batch\", leave=False):\n","\n","        # Separate inputs and targets\n","        inputs = data[:, :-1].unsqueeze(2).to(device)\n","        targets = data[:, -1].to(device)  # Last column is the target (next value)\n","\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Compute the loss\n","        loss = criterion(outputs.squeeze(), targets)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    # Print the average loss per epoch\n","    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}')"]},{"cell_type":"markdown","metadata":{"id":"5nbSzpKLL_NR"},"source":["## Evaluation Loop"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"9nmjzvvnL_NU","scrolled":true,"executionInfo":{"status":"ok","timestamp":1730166065057,"user_tz":420,"elapsed":504,"user":{"displayName":"Nishal Chandra Reddy","userId":"06667136568360495769"}}},"outputs":[],"source":["# Autoregressive prediction function\n","def autoregressive_predict(model, input_matrix, prediction_length):\n","    \"\"\"\n","    Perform autoregressive prediction using the learned model.\n","\n","    Args:\n","    - model: The trained PyTorch model.\n","    - input_matrix: A matrix of initial time steps (e.g., shape (963, window_length)).\n","    - prediction_length: The length of the future trajectory to predict.\n","\n","    Returns:\n","    - output_matrix: A tensor of the predicted future trajectory of the same length as `prediction_length`.\n","    \"\"\"\n","    model.eval()  # Set model to evaluation mode\n","    input_matrix = input_matrix.to(next(model.parameters()).device)  # Move to model's device\n","    output_matrix = torch.empty(input_matrix.shape[0], 0).to(next(model.parameters()).device)  # Initialize on the model's device\n","    current_input = input_matrix\n","\n","\n","    with torch.no_grad():  # No need to calculate gradients for prediction\n","        for _ in range(prediction_length):\n","            # Predict the next time step\n","            next_pred = model(current_input.unsqueeze(2))\n","\n","            # Concatenating the new column along dimension 1 (columns)\n","            output_matrix = torch.cat((output_matrix, next_pred), dim=1)\n","\n","            # Use the predicted value as part of the next input\n","            current_input = torch.cat((current_input[:, 1:],next_pred),dim=1)\n","\n","    return output_matrix"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Ot0-tAqdEKxv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730166086752,"user_tz":420,"elapsed":11356,"user":{"displayName":"Nishal Chandra Reddy","userId":"06667136568360495769"}},"outputId":"521a9921-fab0-4a9e-e4d9-bbe960bed60f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Predictions Tensor Shape: torch.Size([963, 1500])\n","Autoregressive Validation MSE: 0.0021\n"]}],"source":["# Prepare validation and test data\n","train_set = torch.tensor(train_df.values[:, :].astype(np.float32), dtype=torch.float32).to(device) # Move to the appropriate device\n","val_set = torch.tensor(val_df.values[:, :].astype(np.float32), dtype=torch.float32).to(device)   # Move to the appropriate device\n","test_set = torch.tensor(val_df.values[:, :].astype(np.float32), dtype=torch.float32).to(device)  # Move to the appropriate device\n","\n","\n","# Generate predictions for validation set\n","initial_input = train_set[:, -window_length:]  # use the last window of training set as initial input\n","val_predictions_tensor = autoregressive_predict(model, initial_input, val_set.shape[1])\n","print(f\"Validation Predictions Tensor Shape: {val_predictions_tensor.shape}\")\n","\n","# Calculate MSE between predicted trajectories and actual validation trajectories for validation\n","mse_loss = nn.MSELoss()  # Calculate MSE for validation set\n","mse = mse_loss(val_predictions_tensor, val_set)  # Compute MSE\n","print(f\"Autoregressive Validation MSE: {mse.item():.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"RHdAer84L_NX"},"source":["## Plot it out to see what is like"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teMj82fTL_NX"},"outputs":[],"source":["row_idx = 0  # Row index to visualize\n","initial_input = val_set[row_idx, :window_length].unsqueeze(0)\n","\n","# Use the previously generated prediction for the validation set\n","# Move the tensor to CPU before converting to NumPy\n","predicted_trajectory = val_predictions_tensor[row_idx].cpu().numpy()\n","\n","# Get the actual trajectory for comparison\n","# Move the tensor to CPU before converting to NumPy\n","actual_trajectory = val_set[row_idx].cpu().numpy()\n","\n","# Plot the actual vs predicted trajectory\n","plt.figure(figsize=(10, 6))\n","plt.plot(range(len(actual_trajectory)), actual_trajectory, label=\"Actual Trajectory\", color=\"blue\", marker=\"o\")\n","plt.plot(range(len(predicted_trajectory)), predicted_trajectory, label=\"Predicted Trajectory\", color=\"red\", linestyle=\"--\", marker=\"x\")\n","plt.title(f\"Actual vs Predicted Trajectory (Row {row_idx})\")\n","plt.xlabel(\"Time Step\")\n","plt.ylabel(\"Value\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"rB41oULAL_NZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730166130519,"user_tz":420,"elapsed":9372,"user":{"displayName":"Nishal Chandra Reddy","userId":"06667136568360495769"}},"outputId":"862007ea-a337-4bd4-e27f-6643b832aa3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Predictions Tensor Shape: torch.Size([963, 1500])\n"]}],"source":["# Generate predictions for the test dataset\n","initial_input = val_predictions_tensor[:, -window_length:]\n","test_predictions_tensor = autoregressive_predict(model, initial_input, test_set.shape[1])\n","\n","print(f\"Test Predictions Tensor Shape: {test_predictions_tensor.shape}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"I_a_f55PL_Nb","executionInfo":{"status":"ok","timestamp":1730166287478,"user_tz":420,"elapsed":60794,"user":{"displayName":"Nishal Chandra Reddy","userId":"06667136568360495769"}}},"outputs":[],"source":["def generate_submissions_v4(pred_val_tensor, pred_test_tensor, original_val_path, original_test_path):\n","    # Read the original validation and testing datasets\n","    original_val_df = pd.read_csv(original_val_path)\n","    original_test_df = pd.read_csv(original_test_path)\n","\n","    # Ensure the shape of pred_val_tensor and pred_test_tensor is correct\n","    assert pred_val_tensor.shape[0] * pred_val_tensor.shape[1] == original_val_df.shape[0] * (original_val_df.shape[1] - 1)\n","    assert pred_test_tensor.shape[0] * pred_test_tensor.shape[1] == original_test_df.shape[0] * (original_test_df.shape[1] - 1)\n","\n","    # Create empty lists to store ids and values\n","    ids = []\n","    values = []\n","\n","    # Process validation set\n","    for col_idx, col in enumerate(original_val_df.columns[1:]):  # Skip the 'ids' column\n","        for row_idx, _ in enumerate(original_val_df[col]):\n","            ids.append(str(f\"{col}_traffic_val_{row_idx}\"))\n","            values.append(float(pred_val_tensor[row_idx, col_idx]))\n","\n","    # Process testing set\n","    for col_idx, col in enumerate(original_test_df.columns[1:]):  # Skip the 'ids' column\n","        for row_idx, _ in enumerate(original_test_df[col]):\n","            ids.append(str(f\"{col}_traffic_test_{row_idx}\"))\n","            values.append(float(pred_test_tensor[row_idx, col_idx]))\n","\n","    # Create the submissions dataframe\n","    submissions_df = pd.DataFrame({\"ids\": ids, \"value\": values})\n","\n","    # Impute any null values\n","    submissions_df.fillna(100, inplace=True)\n","\n","    # Assert the shape of the dataframe\n","    assert submissions_df.shape[1] == 2\n","    assert submissions_df.shape[0] == (original_val_df.shape[0] * (original_val_df.shape[1] - 1)) + (\n","        original_test_df.shape[0] * (original_test_df.shape[1] - 1)\n","    )\n","    assert \"ids\" in submissions_df.columns\n","    assert \"value\" in submissions_df.columns\n","\n","    # Save to CSV\n","    submissions_df.to_csv(\"submissions_v3.csv\", index=False)\n","\n","\n","# Call the function\n","generate_submissions_v4(val_predictions_tensor, test_predictions_tensor, val_path, test_path)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9826512,"sourceId":84270,"sourceType":"competition"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.0"}},"nbformat":4,"nbformat_minor":0}